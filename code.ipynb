{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "6f7bcf9e",
      "metadata": {
        "id": "6f7bcf9e"
      },
      "source": [
        "# CS541 Applied Machine Learning Spring 2025 - Class Challenge\n",
        "\n",
        "In this class challenge assignment, you will be building a machine learning model to predict the price of an Airbnb rental, given the dataset we have provided. Total points: **100 pts**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ac1a309c",
      "metadata": {
        "id": "ac1a309c"
      },
      "source": [
        "To submit your solution, you need to submit a python (.py) file named challenge.py on Gradescope.\n",
        "Initial Submission due on April 22, 2025\n",
        "Final Submission due May 1, 2025\n",
        "\n",
        "The top-3 winners will present their methodology on the last day of class (May 1st). Instructions on the presentation to follow.\n",
        "\n",
        "There will be a Leaderboard for the challenge that can be seen by all students. USE YOUR FULL NAME AND NO NICKNAMES."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f5dd172",
      "metadata": {
        "id": "9f5dd172"
      },
      "source": [
        "To encourage you to get started early on the challenge, you are required to submit an initial submission due on **April 22**. For this submission, your model needs to achieve a MSE of 0.16 or lower denoted as Baseline1.csv in the Kaggle Leaderboard. The final submission will be due on **May 1**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "27cf921c",
      "metadata": {
        "id": "27cf921c"
      },
      "source": [
        "## Problem and dataset description\n",
        "Pricing a rental property such as an apartment or house on Airbnb is a difficult challenge. A model that accurately predicts the price can potentially help renters and hosts on the platform make better decisions. In this assignment, your task is to train a model that takes features of a listing as input and predicts the price.\n",
        "\n",
        "We have provided you with a dataset collected from the Airbnb website for New York, which has a total of 29,985 entries, each with 765 features. You may use the provided data as you wish in development. We will train your submitted code on the same provided dataset, and will evaluate it on 2 other test sets (one public, and one hidden during the challenge).\n",
        "\n",
        "We have already done some minimal data cleaning for you, such as converting text fields into categorical values and getting rid of the NaN values. To convert text fields into categorical values, we used different strategies depending on the field. For example, sentiment analysis was applied to convert user reviews to numerical values ('comments' column). We added different columns for state names, '1' indicating the location of the property. Column names are included in the data files and are mostly descriptive.\n",
        "\n",
        "Also in this data cleaning step, the price value that we are trying to predict is calculated by taking the log of original price. Hence, the minimum value for our output price is around 2.302 and maximum value is around 9.21 on the training set.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "90de1040",
      "metadata": {
        "id": "90de1040"
      },
      "source": [
        "## Datasets and Codebase\n",
        "\n",
        "Please download the zip file from the link posted on Piazza/Resources.\n",
        "In this notebook, we implemented a linear regression model with random weights (**attached in the end**). For datasets, there’re 2 CSV files for features and labels:\n",
        "\n",
        "    challenge.ipynb (This file: you need to add your code in here, convert it to .py to submit)\n",
        "    data_cleaned_train_comments_X.csv\n",
        "    data_cleaned_train_y.csv\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2975d36d",
      "metadata": {
        "id": "2975d36d"
      },
      "source": [
        "## Instructions to build your model\n",
        "1.  Implement your model in **challenge.ipynb**. You need to modify the *train()* and *predict()* methods of **Model** class (*attached at the end of this notebook*). You can also add other methods/attributes  to the class, or even add new classes in the same file if needed, but do NOT change the signatures of the *train()* and *predict()* as we will call these 2 methods for evaluating your model.\n",
        "\n",
        "2. To submit, you need to convert your notebook (.ipynb) to a python **(.py)** file. Make sure in the python file, it has a class named **Model**, and in the class, there are two methods: *train* and *predict*. Other experimental code should be removed if needed to avoid time limit exceeded on gradescope.\n",
        "\n",
        "3.  You can submit your code on gradescope to test your model. You can submit as many times you like. The last submission will count as the final model.\n",
        "\n",
        "An example linear regression model with random weights is provided to you in this notebook. Please take a look and replace the code with your own.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0ceafaf4",
      "metadata": {
        "id": "0ceafaf4"
      },
      "source": [
        "## Evaluation\n",
        "\n",
        "We will evaluate your model as follows\n",
        "\n",
        "    model = Model() # Model class imported from your submission\n",
        "    X_train = pd.read_csv(\"data_cleaned_train_comments_X.csv\")  # pandas Dataframe\n",
        "    y_train = pd.read_csv(\"data_cleaned_train_y.csv\")  # pandas Dataframe\n",
        "    model.train(X_train, y_train) # train your model on the dataset provided to you\n",
        "    y_pred = model.predict(X_test) # test your model on the hidden test set (pandas Dataframe)\n",
        "    mse = mean_squared_error(y_test, y_pred) # compute mean squared error\n",
        "\n",
        "\n",
        "**There will be 2 test sets, one is public which means you can see MSE on this test set on the Leaderboard (denoted as *MSE (PUBLIC TESTSET)*), and the other one is hidden during the challenge (denoted as *MSE (HIDDEN TESTSET)*)**.\n",
        "Your score on the hidden test set will be your performance measure. So, don’t try to overfit your model on the public test set. Your final grade will depend on the following criteria:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "21fed96b",
      "metadata": {
        "id": "21fed96b"
      },
      "source": [
        "1.  \tIs it original code (implemented by you)? Use of Generative AI to generate code will be flagged as academic misconduct and will be reported to the Academic Conduct Committee (ACC)\n",
        "2.  \tDoes it take a reasonable time to complete?\n",
        "    Your model needs to finish running in under 40 minutes on our machine. We run the code on a machine with 4 CPUs, 6.0GB RAM.\n",
        "3.  \tDoes it achieve a reasonable MSE?\n",
        "    - **Initial submission (10 pts)**: Your model has to be better than the simplest model results which should be a MSE of 0.16 or lower denoted as Baseline1.csv in the leaderboard. Note this will due on **April 22**.\n",
        "    \n",
        "    The grade will be linearly interpolated for the submissions that lie in between the checkpoints above. We will use MSE on the hidden test set to evaluate your model (lower is better).\n",
        "\n",
        "    **Bonus**: **Top 3** with the best MSE on the hidden test set will get a 5 point bonus."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "OxWbj0VbXQmT",
      "metadata": {
        "id": "OxWbj0VbXQmT"
      },
      "source": [
        "# Answer the below questions (in the final submission due on May 1st)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "hO-1KGKaXS4I",
      "metadata": {
        "id": "hO-1KGKaXS4I"
      },
      "source": [
        "1. What are the top-5 features contributed the most towards the performance? How did you identify these features? Your answer should be between 300-350 words.\n",
        "\n",
        "2. What are the top-5 features contributed the least towards the performance? Your answer should be between 300-350 words.\n",
        "\n",
        "3. Share the training and validation loss plots\n",
        "Title of the plot should indicate the number of training / validation data points used.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "G_N8us4LXWRi",
      "metadata": {
        "id": "G_N8us4LXWRi"
      },
      "source": [
        "# Notes & Code"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d21b02dd",
      "metadata": {
        "id": "d21b02dd"
      },
      "source": [
        "**Note 1: This is a regression problem** in which we want to predict the price for an AirBnB property. You should try different models and finetune their hyper parameters.  A little feature engineering can also help to boost the performance.\n",
        "\n",
        "**Note 2**: You may NOT use additional datasets. This assignment is meant to challenge you to build a better model, not collect more training data, so please only use the data we provided. We tested the code on Python 3.10 and 3.9, thus it’s highly recommended to use these Python versions for the challenge.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d0423bd7",
      "metadata": {
        "id": "d0423bd7"
      },
      "source": [
        "In this challenge, you can only use built-in python modules, and these following:\n",
        "- Numpy\n",
        "- pandas\n",
        "- scikit_learn\n",
        "- matplotlib\n",
        "- scipy\n",
        "- torchsummary\n",
        "- xgboost\n",
        "- torchmetrics\n",
        "- lightgbm\n",
        "- catboost\n",
        "- torch\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 268,
      "id": "49f69c67",
      "metadata": {
        "id": "49f69c67"
      },
      "outputs": [],
      "source": [
        "from typing import Tuple\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_selection import SelectKBest, f_regression\n",
        "from xgboost import DMatrix, train as xgb_train\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "class MLPRegressor(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super().__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            # nn.Linear(input_dim, 256),\n",
        "            # nn.ReLU(),\n",
        "            # nn.Dropout(0.3),\n",
        "\n",
        "            # nn.Linear(256, 128),\n",
        "            # nn.ReLU(),\n",
        "            # nn.Dropout(0.3),\n",
        "\n",
        "            # nn.Linear(128, 64),\n",
        "            # nn.ReLU(),\n",
        "            # nn.Dropout(0.2),\n",
        "            # nn.Linear(64, 1)\n",
        "\n",
        "            nn.Linear(input_dim, 24),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "\n",
        "            # nn.Linear(64, 32),\n",
        "            # nn.ReLU(),\n",
        "            # nn.Dropout(0.3),\n",
        "\n",
        "            # nn.Linear(64, 64),\n",
        "            # nn.ReLU(),\n",
        "            # nn.Dropout(0.2),\n",
        "\n",
        "            nn.Linear(24, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "class Model:\n",
        "    def __init__(self):\n",
        "        self.selector = None\n",
        "        self.scaler = None\n",
        "        self.model = None\n",
        "        self.k_features = 100\n",
        "        self.device = 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
        "\n",
        "    def train(self, X_train: pd.DataFrame, y_train: pd.DataFrame) -> None:\n",
        "        if 'id' in X_train.columns:\n",
        "            X_train = X_train.drop(columns=['id'])\n",
        "        y_train = y_train['price'].values.reshape(-1, 1)\n",
        "\n",
        "        self.selector = SelectKBest(score_func=f_regression, k=self.k_features)\n",
        "        X_selected = self.selector.fit_transform(X_train, y_train)\n",
        "\n",
        "        self.scaler = StandardScaler()\n",
        "        X_scaled = self.scaler.fit_transform(X_selected)\n",
        "\n",
        "        X_tensor = torch.tensor(X_scaled, dtype=torch.float32).to(self.device)\n",
        "        y_tensor = torch.tensor(y_train, dtype=torch.float32).to(self.device)\n",
        "\n",
        "        self.model = MLPRegressor(input_dim=X_scaled.shape[1]).to(self.device)\n",
        "        optimizer = optim.Adam(self.model.parameters(), lr=2e-3)\n",
        "        loss_fn = nn.MSELoss()\n",
        "\n",
        "        self.model.train()\n",
        "        for epoch in range(6500):\n",
        "            optimizer.zero_grad()\n",
        "            output = self.model(X_tensor)\n",
        "            loss = loss_fn(output, y_tensor)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            if epoch % 100 == 0:\n",
        "                print(f\"Epoch {epoch}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "    def predict(self, X_test: pd.DataFrame) -> np.array:\n",
        "        if 'id' in X_test.columns:\n",
        "            X_test = X_test.drop(columns=['id'])\n",
        "        X_selected = self.selector.transform(X_test)\n",
        "        X_scaled = self.scaler.transform(X_selected)\n",
        "\n",
        "        X_tensor = torch.tensor(X_scaled, dtype=torch.float32).to(self.device)\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            y_pred = self.model(X_tensor).cpu().numpy()\n",
        "        return y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 269,
      "id": "17a72415",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/spectual/miniconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0, Loss: 22.7976\n",
            "Epoch 100, Loss: 2.3754\n",
            "Epoch 200, Loss: 1.6926\n",
            "Epoch 300, Loss: 1.4786\n",
            "Epoch 400, Loss: 1.3383\n",
            "Epoch 500, Loss: 1.1868\n",
            "Epoch 600, Loss: 1.0799\n",
            "Epoch 700, Loss: 0.9863\n",
            "Epoch 800, Loss: 0.9212\n",
            "Epoch 900, Loss: 0.8662\n",
            "Epoch 1000, Loss: 0.8320\n",
            "Epoch 1100, Loss: 0.7995\n",
            "Epoch 1200, Loss: 0.7655\n",
            "Epoch 1300, Loss: 0.7360\n",
            "Epoch 1400, Loss: 0.7265\n",
            "Epoch 1500, Loss: 0.7002\n",
            "Epoch 1600, Loss: 0.6954\n",
            "Epoch 1700, Loss: 0.6745\n",
            "Epoch 1800, Loss: 0.6516\n",
            "Epoch 1900, Loss: 0.6334\n",
            "Epoch 2000, Loss: 0.6133\n",
            "Epoch 2100, Loss: 0.5913\n",
            "Epoch 2200, Loss: 0.5773\n",
            "Epoch 2300, Loss: 0.5613\n",
            "Epoch 2400, Loss: 0.5457\n",
            "Epoch 2500, Loss: 0.5324\n",
            "Epoch 2600, Loss: 0.5110\n",
            "Epoch 2700, Loss: 0.5013\n",
            "Epoch 2800, Loss: 0.4723\n",
            "Epoch 2900, Loss: 0.4698\n",
            "Epoch 3000, Loss: 0.4542\n",
            "Epoch 3100, Loss: 0.4359\n",
            "Epoch 3200, Loss: 0.4191\n",
            "Epoch 3300, Loss: 0.4132\n",
            "Epoch 3400, Loss: 0.3943\n",
            "Epoch 3500, Loss: 0.3785\n",
            "Epoch 3600, Loss: 0.3616\n",
            "Epoch 3700, Loss: 0.3511\n",
            "Epoch 3800, Loss: 0.3328\n",
            "Epoch 3900, Loss: 0.3206\n",
            "Epoch 4000, Loss: 0.3087\n",
            "Epoch 4100, Loss: 0.3004\n",
            "Epoch 4200, Loss: 0.2853\n",
            "Epoch 4300, Loss: 0.2793\n",
            "Epoch 4400, Loss: 0.2685\n",
            "Epoch 4500, Loss: 0.2573\n",
            "Epoch 4600, Loss: 0.2452\n",
            "Epoch 4700, Loss: 0.2394\n",
            "Epoch 4800, Loss: 0.2305\n",
            "Epoch 4900, Loss: 0.2246\n",
            "Epoch 5000, Loss: 0.2174\n",
            "Epoch 5100, Loss: 0.2114\n",
            "Epoch 5200, Loss: 0.2023\n",
            "Epoch 5300, Loss: 0.1957\n",
            "Epoch 5400, Loss: 0.1920\n",
            "Epoch 5500, Loss: 0.1876\n",
            "Epoch 5600, Loss: 0.1848\n",
            "Epoch 5700, Loss: 0.1797\n",
            "Epoch 5800, Loss: 0.1770\n",
            "Epoch 5900, Loss: 0.1719\n",
            "Epoch 6000, Loss: 0.1715\n",
            "Epoch 6100, Loss: 0.1697\n",
            "Epoch 6200, Loss: 0.1665\n",
            "Epoch 6300, Loss: 0.1652\n",
            "Epoch 6400, Loss: 0.1638\n"
          ]
        }
      ],
      "source": [
        "# Local testing\n",
        "X = pd.read_csv(\"./data/trainData.csv\")\n",
        "y = pd.read_csv(\"./data/trainLabel.csv\")\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "model = Model()\n",
        "model.train(X_train, y_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 270,
      "id": "fc4c4dbf",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train MSE: 0.1386\n",
            "MSE: 0.1465\n"
          ]
        }
      ],
      "source": [
        "\n",
        "y_pred_train = model.predict(X_train)\n",
        "train_mse = mean_squared_error(y_train['price'], y_pred_train, squared=True)\n",
        "print(f\"Train MSE: {train_mse:.4f}\")\n",
        "y_pred = model.predict(X_val)\n",
        "mse = mean_squared_error(y_val['price'], y_pred, squared=True)\n",
        "print(f\"MSE: {mse:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "id": "8e904f50",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Truncate the dataset\n",
        "part_X_train = X.sample(frac=0.1, random_state=42)\n",
        "part_y_train = y.sample(frac=0.1, random_state=42)\n",
        "part_X_train.to_csv(\"./data/part_train.csv\", index=False)\n",
        "part_y_train.to_csv(\"./data/part_label.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 267,
      "id": "d6c81167",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/spectual/miniconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0, Loss: 21.4944\n",
            "Epoch 100, Loss: 1.7211\n",
            "Epoch 200, Loss: 1.4094\n",
            "Epoch 300, Loss: 1.1967\n",
            "Epoch 400, Loss: 1.0522\n",
            "Epoch 500, Loss: 0.9292\n",
            "Epoch 600, Loss: 0.8664\n",
            "Epoch 700, Loss: 0.7824\n",
            "Epoch 800, Loss: 0.7195\n",
            "Epoch 900, Loss: 0.6883\n",
            "Epoch 1000, Loss: 0.6627\n",
            "Epoch 1100, Loss: 0.6292\n",
            "Epoch 1200, Loss: 0.6130\n",
            "Epoch 1300, Loss: 0.5836\n",
            "Epoch 1400, Loss: 0.5616\n",
            "Epoch 1500, Loss: 0.5650\n",
            "Epoch 1600, Loss: 0.5469\n",
            "Epoch 1700, Loss: 0.5339\n",
            "Epoch 1800, Loss: 0.5263\n",
            "Epoch 1900, Loss: 0.5071\n",
            "Epoch 2000, Loss: 0.4981\n",
            "Epoch 2100, Loss: 0.4899\n",
            "Epoch 2200, Loss: 0.4768\n",
            "Epoch 2300, Loss: 0.4637\n",
            "Epoch 2400, Loss: 0.4548\n",
            "Epoch 2500, Loss: 0.4436\n",
            "Epoch 2600, Loss: 0.4355\n",
            "Epoch 2700, Loss: 0.4224\n",
            "Epoch 2800, Loss: 0.4107\n",
            "Epoch 2900, Loss: 0.4028\n",
            "Epoch 3000, Loss: 0.3953\n",
            "Epoch 3100, Loss: 0.3880\n",
            "Epoch 3200, Loss: 0.3667\n",
            "Epoch 3300, Loss: 0.3624\n",
            "Epoch 3400, Loss: 0.3471\n",
            "Epoch 3500, Loss: 0.3371\n",
            "Epoch 3600, Loss: 0.3252\n",
            "Epoch 3700, Loss: 0.3207\n",
            "Epoch 3800, Loss: 0.3100\n",
            "Epoch 3900, Loss: 0.3012\n",
            "Epoch 4000, Loss: 0.2916\n",
            "Epoch 4100, Loss: 0.2788\n",
            "Epoch 4200, Loss: 0.2736\n",
            "Epoch 4300, Loss: 0.2651\n",
            "Epoch 4400, Loss: 0.2564\n",
            "Epoch 4500, Loss: 0.2485\n",
            "Epoch 4600, Loss: 0.2412\n",
            "Epoch 4700, Loss: 0.2306\n",
            "Epoch 4800, Loss: 0.2243\n",
            "Epoch 4900, Loss: 0.2197\n",
            "Epoch 5000, Loss: 0.2129\n",
            "Epoch 5100, Loss: 0.2055\n",
            "Epoch 5200, Loss: 0.2027\n",
            "Epoch 5300, Loss: 0.1949\n",
            "Epoch 5400, Loss: 0.1946\n",
            "Epoch 5500, Loss: 0.1868\n",
            "Epoch 5600, Loss: 0.1810\n",
            "Epoch 5700, Loss: 0.1780\n",
            "Epoch 5800, Loss: 0.1743\n",
            "Epoch 5900, Loss: 0.1719\n",
            "Epoch 6000, Loss: 0.1683\n",
            "Epoch 6100, Loss: 0.1658\n",
            "Epoch 6200, Loss: 0.1638\n",
            "Epoch 6300, Loss: 0.1628\n",
            "Epoch 6400, Loss: 0.1611\n"
          ]
        }
      ],
      "source": [
        "model = Model() # Model class imported from your submission\n",
        "X_train = pd.read_csv(\"./data/trainData.csv\")  # pandas Dataframe\n",
        "y_train = pd.read_csv(\"./data/trainLabel.csv\")  # pandas Dataframe\n",
        "model.train(X_train, y_train) # train your model on the dataset provided to you\n",
        "X_test = pd.read_csv(\"./data/testingData.csv\") # pandas Dataframe\n",
        "y_pred = model.predict(X_test) # test your model on the hidden test set (pandas Dataframe)\n",
        "# mse = mean_squared_error(y_test, y_pred) # compute mean squared error\n",
        "\n",
        "# Keep id and price columns to submission.csv\n",
        "submission = pd.DataFrame({\n",
        "    'id': X_test['id'],\n",
        "    'price': y_pred.flatten()\n",
        "})\n",
        "submission.to_csv(\"./data/submission.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "001404a3",
      "metadata": {
        "id": "001404a3"
      },
      "source": [
        "**GOOD LUCK!**\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "OxWbj0VbXQmT"
      ],
      "provenance": []
    },
    "hide_input": false,
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
