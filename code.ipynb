{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "6f7bcf9e",
      "metadata": {
        "id": "6f7bcf9e"
      },
      "source": [
        "# CS541 Applied Machine Learning Spring 2025 - Class Challenge\n",
        "\n",
        "In this class challenge assignment, you will be building a machine learning model to predict the price of an Airbnb rental, given the dataset we have provided. Total points: **100 pts**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ac1a309c",
      "metadata": {
        "id": "ac1a309c"
      },
      "source": [
        "To submit your solution, you need to submit a python (.py) file named challenge.py on Gradescope.\n",
        "Initial Submission due on April 22, 2025\n",
        "Final Submission due May 1, 2025\n",
        "\n",
        "The top-3 winners will present their methodology on the last day of class (May 1st). Instructions on the presentation to follow.\n",
        "\n",
        "There will be a Leaderboard for the challenge that can be seen by all students. USE YOUR FULL NAME AND NO NICKNAMES."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f5dd172",
      "metadata": {
        "id": "9f5dd172"
      },
      "source": [
        "To encourage you to get started early on the challenge, you are required to submit an initial submission due on **April 22**. For this submission, your model needs to achieve a MSE of 0.16 or lower denoted as Baseline1.csv in the Kaggle Leaderboard. The final submission will be due on **May 1**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "27cf921c",
      "metadata": {
        "id": "27cf921c"
      },
      "source": [
        "## Problem and dataset description\n",
        "Pricing a rental property such as an apartment or house on Airbnb is a difficult challenge. A model that accurately predicts the price can potentially help renters and hosts on the platform make better decisions. In this assignment, your task is to train a model that takes features of a listing as input and predicts the price.\n",
        "\n",
        "We have provided you with a dataset collected from the Airbnb website for New York, which has a total of 29,985 entries, each with 765 features. You may use the provided data as you wish in development. We will train your submitted code on the same provided dataset, and will evaluate it on 2 other test sets (one public, and one hidden during the challenge).\n",
        "\n",
        "We have already done some minimal data cleaning for you, such as converting text fields into categorical values and getting rid of the NaN values. To convert text fields into categorical values, we used different strategies depending on the field. For example, sentiment analysis was applied to convert user reviews to numerical values ('comments' column). We added different columns for state names, '1' indicating the location of the property. Column names are included in the data files and are mostly descriptive.\n",
        "\n",
        "Also in this data cleaning step, the price value that we are trying to predict is calculated by taking the log of original price. Hence, the minimum value for our output price is around 2.302 and maximum value is around 9.21 on the training set.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "90de1040",
      "metadata": {
        "id": "90de1040"
      },
      "source": [
        "## Datasets and Codebase\n",
        "\n",
        "Please download the zip file from the link posted on Piazza/Resources.\n",
        "In this notebook, we implemented a linear regression model with random weights (**attached in the end**). For datasets, there’re 2 CSV files for features and labels:\n",
        "\n",
        "    challenge.ipynb (This file: you need to add your code in here, convert it to .py to submit)\n",
        "    data_cleaned_train_comments_X.csv\n",
        "    data_cleaned_train_y.csv\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2975d36d",
      "metadata": {
        "id": "2975d36d"
      },
      "source": [
        "## Instructions to build your model\n",
        "1.  Implement your model in **challenge.ipynb**. You need to modify the *train()* and *predict()* methods of **Model** class (*attached at the end of this notebook*). You can also add other methods/attributes  to the class, or even add new classes in the same file if needed, but do NOT change the signatures of the *train()* and *predict()* as we will call these 2 methods for evaluating your model.\n",
        "\n",
        "2. To submit, you need to convert your notebook (.ipynb) to a python **(.py)** file. Make sure in the python file, it has a class named **Model**, and in the class, there are two methods: *train* and *predict*. Other experimental code should be removed if needed to avoid time limit exceeded on gradescope.\n",
        "\n",
        "3.  You can submit your code on gradescope to test your model. You can submit as many times you like. The last submission will count as the final model.\n",
        "\n",
        "An example linear regression model with random weights is provided to you in this notebook. Please take a look and replace the code with your own.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0ceafaf4",
      "metadata": {
        "id": "0ceafaf4"
      },
      "source": [
        "## Evaluation\n",
        "\n",
        "We will evaluate your model as follows\n",
        "\n",
        "    model = Model() # Model class imported from your submission\n",
        "    X_train = pd.read_csv(\"data_cleaned_train_comments_X.csv\")  # pandas Dataframe\n",
        "    y_train = pd.read_csv(\"data_cleaned_train_y.csv\")  # pandas Dataframe\n",
        "    model.train(X_train, y_train) # train your model on the dataset provided to you\n",
        "    y_pred = model.predict(X_test) # test your model on the hidden test set (pandas Dataframe)\n",
        "    mse = mean_squared_error(y_test, y_pred) # compute mean squared error\n",
        "\n",
        "\n",
        "**There will be 2 test sets, one is public which means you can see MSE on this test set on the Leaderboard (denoted as *MSE (PUBLIC TESTSET)*), and the other one is hidden during the challenge (denoted as *MSE (HIDDEN TESTSET)*)**.\n",
        "Your score on the hidden test set will be your performance measure. So, don’t try to overfit your model on the public test set. Your final grade will depend on the following criteria:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "21fed96b",
      "metadata": {
        "id": "21fed96b"
      },
      "source": [
        "1.  \tIs it original code (implemented by you)? Use of Generative AI to generate code will be flagged as academic misconduct and will be reported to the Academic Conduct Committee (ACC)\n",
        "2.  \tDoes it take a reasonable time to complete?\n",
        "    Your model needs to finish running in under 40 minutes on our machine. We run the code on a machine with 4 CPUs, 6.0GB RAM.\n",
        "3.  \tDoes it achieve a reasonable MSE?\n",
        "    - **Initial submission (10 pts)**: Your model has to be better than the simplest model results which should be a MSE of 0.16 or lower denoted as Baseline1.csv in the leaderboard. Note this will due on **April 22**.\n",
        "    \n",
        "    The grade will be linearly interpolated for the submissions that lie in between the checkpoints above. We will use MSE on the hidden test set to evaluate your model (lower is better).\n",
        "\n",
        "    **Bonus**: **Top 3** with the best MSE on the hidden test set will get a 5 point bonus."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "OxWbj0VbXQmT",
      "metadata": {
        "id": "OxWbj0VbXQmT"
      },
      "source": [
        "# Answer the below questions (in the final submission due on May 1st)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "hO-1KGKaXS4I",
      "metadata": {
        "id": "hO-1KGKaXS4I"
      },
      "source": [
        "1. What are the top-5 features contributed the most towards the performance? How did you identify these features? Your answer should be between 300-350 words.\n",
        "\n",
        "2. What are the top-5 features contributed the least towards the performance? Your answer should be between 300-350 words.\n",
        "\n",
        "3. Share the training and validation loss plots\n",
        "Title of the plot should indicate the number of training / validation data points used.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "G_N8us4LXWRi",
      "metadata": {
        "id": "G_N8us4LXWRi"
      },
      "source": [
        "# Notes & Code"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d21b02dd",
      "metadata": {
        "id": "d21b02dd"
      },
      "source": [
        "**Note 1: This is a regression problem** in which we want to predict the price for an AirBnB property. You should try different models and finetune their hyper parameters.  A little feature engineering can also help to boost the performance.\n",
        "\n",
        "**Note 2**: You may NOT use additional datasets. This assignment is meant to challenge you to build a better model, not collect more training data, so please only use the data we provided. We tested the code on Python 3.10 and 3.9, thus it’s highly recommended to use these Python versions for the challenge.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d0423bd7",
      "metadata": {
        "id": "d0423bd7"
      },
      "source": [
        "In this challenge, you can only use built-in python modules, and these following:\n",
        "- Numpy\n",
        "- pandas\n",
        "- scikit_learn\n",
        "- matplotlib\n",
        "- scipy\n",
        "- torchsummary\n",
        "- xgboost\n",
        "- torchmetrics\n",
        "- lightgbm\n",
        "- catboost\n",
        "- torch\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "49f69c67",
      "metadata": {
        "id": "49f69c67"
      },
      "outputs": [],
      "source": [
        "from typing import Tuple\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.feature_selection import SelectKBest, f_regression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from xgboost import DMatrix, train as xgb_train\n",
        "\n",
        "class Model:\n",
        "    def __init__(self):\n",
        "        self.selector = None\n",
        "        self.model = None\n",
        "        self.k_features = 700\n",
        "        self.xgb_params = {\n",
        "            'objective': 'reg:squarederror',\n",
        "            'eval_metric': 'rmse',\n",
        "            'eta': 0.0045,                  \n",
        "            'max_depth': 6,                  \n",
        "            'colsample_bytree': 0.6,      \n",
        "            'min_child_weight': 40,          \n",
        "            'alpha': 2.3,                \n",
        "            'lambda': 0.065,           \n",
        "            'subsample': 0.8,               \n",
        "            'seed': 42\n",
        "        }\n",
        "        self.early_stopping_rounds = 20\n",
        "        self.num_boost_round = 5000         \n",
        "\n",
        "    def train(self, X_train: pd.DataFrame, y_train: pd.DataFrame) -> None:\n",
        "        if 'id' in X_train.columns:\n",
        "            X_train = X_train.drop(columns=['id'])\n",
        "\n",
        "        y_train = y_train['price']\n",
        "\n",
        "        self.selector = SelectKBest(score_func=f_regression, k=self.k_features)\n",
        "        X_selected = self.selector.fit_transform(X_train, y_train)\n",
        "\n",
        "        X_tr, X_val, y_tr, y_val = train_test_split(\n",
        "            X_selected, y_train, test_size=0.1, random_state=42\n",
        "        )\n",
        "\n",
        "        dtrain = DMatrix(X_tr, label=y_tr)\n",
        "        dval = DMatrix(X_val, label=y_val)\n",
        "\n",
        "        self.model = xgb_train(\n",
        "            self.xgb_params,\n",
        "            dtrain,\n",
        "            num_boost_round=self.num_boost_round,\n",
        "            evals=[(dtrain, 'train'), (dval, 'eval')],\n",
        "            early_stopping_rounds=self.early_stopping_rounds,\n",
        "            verbose_eval=False\n",
        "        )\n",
        "\n",
        "    def predict(self, X_test: pd.DataFrame) -> np.ndarray:\n",
        "        if 'id' in X_test.columns:\n",
        "            X_test = X_test.drop(columns=['id'])\n",
        "        X_selected = self.selector.transform(X_test)\n",
        "        dtest = DMatrix(X_selected)\n",
        "        y_pred = self.model.predict(dtest)\n",
        "        return y_pred.reshape(-1, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "17a72415",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train MSE: 0.0976\n",
            "Valid MSE: 0.1251\n",
            "Valid MSE - Train MSE: 0.0276\n"
          ]
        }
      ],
      "source": [
        "X = pd.read_csv(\"./data/trainData.csv\")\n",
        "y = pd.read_csv(\"./data/trainLabel.csv\")\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.4, random_state=42)\n",
        "model = Model()\n",
        "model.train(X_train, y_train)\n",
        "\n",
        "y_pred_train = model.predict(X_train)\n",
        "train_mse = mean_squared_error(y_train['price'], y_pred_train)\n",
        "print(f\"Train MSE: {train_mse:.4f}\")\n",
        "y_pred = model.predict(X_val)\n",
        "mse = mean_squared_error(y_val['price'], y_pred)\n",
        "print(f\"Valid MSE: {mse:.4f}\")\n",
        "print(f\"Valid MSE - Train MSE: {mse - train_mse:.4f}\")\n",
        "\n",
        "# Cross-validation\n",
        "# from sklearn.model_selection import KFold\n",
        "# kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "# mse_list = []\n",
        "# for train_index, val_index in kf.split(X):\n",
        "#     X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
        "#     y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
        "#     model.train(X_train, y_train)\n",
        "#     y_pred = model.predict(X_val)\n",
        "#     mse = mean_squared_error(y_val['price'], y_pred)\n",
        "#     mse_list.append(mse)\n",
        "# print(f\"Cross-validation MSE: {np.mean(mse_list):.4f} ± {np.std(mse_list):.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "d6c81167",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train MSE: 0.0993\n"
          ]
        }
      ],
      "source": [
        "model = Model() # Model class imported from your submission\n",
        "X_train = pd.read_csv(\"./data/trainData.csv\")  # pandas Dataframe\n",
        "y_train = pd.read_csv(\"./data/trainLabel.csv\")  # pandas Dataframe\n",
        "model.train(X_train, y_train) # train your model on the dataset provided to you\n",
        "X_test = pd.read_csv(\"./data/testingData.csv\") # pandas Dataframe\n",
        "y_pred = model.predict(X_test) # test your model on the hidden test set (pandas Dataframe)\n",
        "# mse = mean_squared_error(y_test, y_pred) # compute mean squared error\n",
        "\n",
        "# Print training MSE\n",
        "y_pred_train = model.predict(X_train)\n",
        "train_mse = mean_squared_error(y_train['price'], y_pred_train)\n",
        "print(f\"Train MSE: {train_mse:.4f}\")\n",
        "\n",
        "\n",
        "# Keep id and price columns to submission.csv\n",
        "submission = pd.DataFrame({\n",
        "    'id': X_test['id'],\n",
        "    'price': y_pred.flatten()\n",
        "})\n",
        "submission.to_csv(\"./data/submission.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "001404a3",
      "metadata": {
        "id": "001404a3"
      },
      "source": [
        "**GOOD LUCK!**\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "OxWbj0VbXQmT"
      ],
      "provenance": []
    },
    "hide_input": false,
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
